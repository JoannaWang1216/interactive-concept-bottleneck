{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of X [N, C, H, W]: torch.Size([32, 3, 299, 299])\n",
      "Shape of y: torch.Size([32, 312]) torch.int64\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "from torchvision import transforms\n",
    "from concept_model.dataset import CUBImageToAttributes\n",
    "\n",
    "batch_size = 32\n",
    "num_workers = 2\n",
    "\n",
    "train_preprocess = transforms.Compose(\n",
    "    [\n",
    "        transforms.RandomResizedCrop(299),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "    ]\n",
    ")\n",
    "\n",
    "training_data = CUBImageToAttributes(train=True, transform=train_preprocess)\n",
    "test_data = CUBImageToAttributes(train=False)\n",
    "\n",
    "train_dataloader = DataLoader(\n",
    "    training_data, batch_size=batch_size, num_workers=num_workers, shuffle=True\n",
    ")\n",
    "test_dataloader = DataLoader(test_data, batch_size=batch_size, num_workers=num_workers)\n",
    "\n",
    "for X, y in test_dataloader:\n",
    "    print(f\"Shape of X [N, C, H, W]: {X.shape}\")\n",
    "    print(f\"Shape of y: {y.shape} {y.dtype}\")\n",
    "    break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /home/joanna/.cache/torch/hub/pytorch_vision_v0.10.0\n",
      "Downloading: \"https://download.pytorch.org/models/inception_v3_google-0cc3c7bd.pth\" to /home/joanna/.cache/torch/hub/checkpoints/inception_v3_google-0cc3c7bd.pth\n",
      "100.0%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda device\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "model = torch.hub.load(\n",
    "    \"pytorch/vision:v0.10.0\", \"inception_v3\", weights=\"IMAGENET1K_V1\"\n",
    ")\n",
    "model.AuxLogits.fc = torch.nn.Linear(in_features=768, out_features=312)\n",
    "model.fc = torch.nn.Linear(in_features=2048, out_features=312)\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(\"Using {} device\".format(device))\n",
    "model.to(device)\n",
    "\n",
    "loss_fn = torch.nn.BCEWithLogitsLoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=1e-2, momentum=0.9)\n",
    "\n",
    "\n",
    "def train(dataloader, model, loss_fn, optimizer):\n",
    "    size = len(dataloader.dataset)\n",
    "    model.train()\n",
    "    for batch, (X, y) in enumerate(dataloader):\n",
    "        X, y = X.to(device), y.to(torch.float).to(device)\n",
    "        # Compute prediction and loss\n",
    "        logits, aux_logits = model(X)\n",
    "        loss = loss_fn(logits, y) + 0.4 * loss_fn(aux_logits, y)\n",
    "\n",
    "        # Backpropagation\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        if batch % 100 == 0:\n",
    "            loss, current = loss.item(), batch * len(X)\n",
    "            print(f\"loss: {loss:>7f}  [{current:>5d}/{size:>5d}]\")\n",
    "\n",
    "\n",
    "def test(dataloader, model, loss_fn):\n",
    "    size = len(dataloader.dataset)\n",
    "    num_batches = len(dataloader)\n",
    "    model.eval()\n",
    "    test_loss, correct = 0, 0\n",
    "    correct_using_attributes = 0\n",
    "    with torch.no_grad():\n",
    "        for X, y in dataloader:\n",
    "            X, y = X.to(device), y.to(device)\n",
    "            pred = model(X)\n",
    "            test_loss += loss_fn(pred, y.to(torch.float)).item()\n",
    "            correct += (\n",
    "                ((torch.sigmoid(pred) > 0.5).to(torch.int64) == y)\n",
    "                .type(torch.float)\n",
    "                .all(dim=1)\n",
    "                .sum()\n",
    "                .item()\n",
    "            )\n",
    "            correct_attributes = torch.sum(\n",
    "                ((torch.nn.Sigmoid()(pred) > 0.5).to(torch.int64) == y).to(torch.float)\n",
    "            )\n",
    "            num_attributes = y.shape[1]\n",
    "            correct_using_attributes += correct_attributes.item() / num_attributes\n",
    "    test_loss /= num_batches\n",
    "    correct /= size\n",
    "    correct_using_attributes /= size\n",
    "    print(\n",
    "        f\"Test Error: \\n Accuracy: {(100*correct):>0.1f}%, Accuracy (Attribute-wise): {(100*correct_using_attributes):>0.1f}%, Avg loss: {test_loss:>8f} \\n\"\n",
    "    )\n",
    "    return correct_using_attributes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1\n",
      "-------------------------------\n",
      "loss: 0.998570  [    0/ 5994]\n",
      "loss: 0.489658  [ 3200/ 5994]\n",
      "Test Error: \n",
      " Accuracy: 0.0%, Accuracy (Attribute-wise): 90.3%, Avg loss: 0.281488 \n",
      "\n",
      "Epoch 2\n",
      "-------------------------------\n",
      "loss: 0.420159  [    0/ 5994]\n",
      "loss: 0.386683  [ 3200/ 5994]\n",
      "Test Error: \n",
      " Accuracy: 0.0%, Accuracy (Attribute-wise): 90.3%, Avg loss: 0.262413 \n",
      "\n",
      "Epoch 3\n",
      "-------------------------------\n",
      "loss: 0.382060  [    0/ 5994]\n",
      "loss: 0.387880  [ 3200/ 5994]\n",
      "Test Error: \n",
      " Accuracy: 0.0%, Accuracy (Attribute-wise): 90.3%, Avg loss: 0.257335 \n",
      "\n",
      "Epoch 4\n",
      "-------------------------------\n",
      "loss: 0.358059  [    0/ 5994]\n",
      "loss: 0.353023  [ 3200/ 5994]\n",
      "Test Error: \n",
      " Accuracy: 0.0%, Accuracy (Attribute-wise): 90.4%, Avg loss: 0.253840 \n",
      "\n",
      "Epoch 5\n",
      "-------------------------------\n",
      "loss: 0.360708  [    0/ 5994]\n",
      "loss: 0.369440  [ 3200/ 5994]\n",
      "Test Error: \n",
      " Accuracy: 0.0%, Accuracy (Attribute-wise): 90.5%, Avg loss: 0.250520 \n",
      "\n",
      "Epoch 6\n",
      "-------------------------------\n",
      "loss: 0.348521  [    0/ 5994]\n",
      "loss: 0.323705  [ 3200/ 5994]\n",
      "Test Error: \n",
      " Accuracy: 0.0%, Accuracy (Attribute-wise): 90.6%, Avg loss: 0.246401 \n",
      "\n",
      "Epoch 7\n",
      "-------------------------------\n",
      "loss: 0.337936  [    0/ 5994]\n",
      "loss: 0.338410  [ 3200/ 5994]\n",
      "Test Error: \n",
      " Accuracy: 0.0%, Accuracy (Attribute-wise): 90.7%, Avg loss: 0.241336 \n",
      "\n",
      "Epoch 8\n",
      "-------------------------------\n",
      "loss: 0.366100  [    0/ 5994]\n",
      "loss: 0.336314  [ 3200/ 5994]\n",
      "Test Error: \n",
      " Accuracy: 0.0%, Accuracy (Attribute-wise): 90.9%, Avg loss: 0.236960 \n",
      "\n",
      "Epoch 9\n",
      "-------------------------------\n",
      "loss: 0.337924  [    0/ 5994]\n",
      "loss: 0.356283  [ 3200/ 5994]\n",
      "Test Error: \n",
      " Accuracy: 0.0%, Accuracy (Attribute-wise): 91.0%, Avg loss: 0.232793 \n",
      "\n",
      "Epoch 10\n",
      "-------------------------------\n",
      "loss: 0.329834  [    0/ 5994]\n",
      "loss: 0.317919  [ 3200/ 5994]\n",
      "Test Error: \n",
      " Accuracy: 0.0%, Accuracy (Attribute-wise): 91.1%, Avg loss: 0.229399 \n",
      "\n",
      "Epoch 11\n",
      "-------------------------------\n",
      "loss: 0.327901  [    0/ 5994]\n",
      "loss: 0.330333  [ 3200/ 5994]\n",
      "Test Error: \n",
      " Accuracy: 0.0%, Accuracy (Attribute-wise): 91.2%, Avg loss: 0.226816 \n",
      "\n",
      "Epoch 12\n",
      "-------------------------------\n",
      "loss: 0.339280  [    0/ 5994]\n",
      "loss: 0.329210  [ 3200/ 5994]\n",
      "Test Error: \n",
      " Accuracy: 0.0%, Accuracy (Attribute-wise): 91.2%, Avg loss: 0.224872 \n",
      "\n",
      "Epoch 13\n",
      "-------------------------------\n",
      "loss: 0.326254  [    0/ 5994]\n",
      "loss: 0.332356  [ 3200/ 5994]\n",
      "Test Error: \n",
      " Accuracy: 0.0%, Accuracy (Attribute-wise): 91.3%, Avg loss: 0.222972 \n",
      "\n",
      "Epoch 14\n",
      "-------------------------------\n",
      "loss: 0.313673  [    0/ 5994]\n",
      "loss: 0.313943  [ 3200/ 5994]\n",
      "Test Error: \n",
      " Accuracy: 0.0%, Accuracy (Attribute-wise): 91.3%, Avg loss: 0.221461 \n",
      "\n",
      "Epoch 15\n",
      "-------------------------------\n",
      "loss: 0.325482  [    0/ 5994]\n",
      "loss: 0.313496  [ 3200/ 5994]\n",
      "Test Error: \n",
      " Accuracy: 0.0%, Accuracy (Attribute-wise): 91.4%, Avg loss: 0.219773 \n",
      "\n",
      "Epoch 16\n",
      "-------------------------------\n",
      "loss: 0.299096  [    0/ 5994]\n",
      "loss: 0.297846  [ 3200/ 5994]\n",
      "Test Error: \n",
      " Accuracy: 0.0%, Accuracy (Attribute-wise): 91.4%, Avg loss: 0.218570 \n",
      "\n",
      "Epoch 17\n",
      "-------------------------------\n",
      "loss: 0.302190  [    0/ 5994]\n",
      "loss: 0.303576  [ 3200/ 5994]\n",
      "Test Error: \n",
      " Accuracy: 0.0%, Accuracy (Attribute-wise): 91.5%, Avg loss: 0.217736 \n",
      "\n",
      "Epoch 18\n",
      "-------------------------------\n",
      "loss: 0.310820  [    0/ 5994]\n",
      "loss: 0.329503  [ 3200/ 5994]\n",
      "Test Error: \n",
      " Accuracy: 0.0%, Accuracy (Attribute-wise): 91.5%, Avg loss: 0.216365 \n",
      "\n",
      "Epoch 19\n",
      "-------------------------------\n",
      "loss: 0.312535  [    0/ 5994]\n",
      "loss: 0.297377  [ 3200/ 5994]\n",
      "Test Error: \n",
      " Accuracy: 0.0%, Accuracy (Attribute-wise): 91.5%, Avg loss: 0.215641 \n",
      "\n",
      "Epoch 20\n",
      "-------------------------------\n",
      "loss: 0.313963  [    0/ 5994]\n",
      "loss: 0.312958  [ 3200/ 5994]\n",
      "Test Error: \n",
      " Accuracy: 0.0%, Accuracy (Attribute-wise): 91.6%, Avg loss: 0.214814 \n",
      "\n",
      "Epoch 21\n",
      "-------------------------------\n",
      "loss: 0.334093  [    0/ 5994]\n",
      "loss: 0.276465  [ 3200/ 5994]\n",
      "Test Error: \n",
      " Accuracy: 0.0%, Accuracy (Attribute-wise): 91.6%, Avg loss: 0.214055 \n",
      "\n",
      "Epoch 22\n",
      "-------------------------------\n",
      "loss: 0.306180  [    0/ 5994]\n",
      "loss: 0.280175  [ 3200/ 5994]\n",
      "Test Error: \n",
      " Accuracy: 0.0%, Accuracy (Attribute-wise): 91.6%, Avg loss: 0.213174 \n",
      "\n",
      "Epoch 23\n",
      "-------------------------------\n",
      "loss: 0.316108  [    0/ 5994]\n",
      "loss: 0.294571  [ 3200/ 5994]\n",
      "Test Error: \n",
      " Accuracy: 0.0%, Accuracy (Attribute-wise): 91.6%, Avg loss: 0.212774 \n",
      "\n",
      "Epoch 24\n",
      "-------------------------------\n",
      "loss: 0.311905  [    0/ 5994]\n",
      "loss: 0.297524  [ 3200/ 5994]\n",
      "Test Error: \n",
      " Accuracy: 0.0%, Accuracy (Attribute-wise): 91.6%, Avg loss: 0.211987 \n",
      "\n",
      "Epoch 25\n",
      "-------------------------------\n",
      "loss: 0.315574  [    0/ 5994]\n",
      "loss: 0.312328  [ 3200/ 5994]\n",
      "Test Error: \n",
      " Accuracy: 0.0%, Accuracy (Attribute-wise): 91.6%, Avg loss: 0.211555 \n",
      "\n",
      "Epoch 26\n",
      "-------------------------------\n",
      "loss: 0.308658  [    0/ 5994]\n",
      "loss: 0.283758  [ 3200/ 5994]\n",
      "Test Error: \n",
      " Accuracy: 0.0%, Accuracy (Attribute-wise): 91.7%, Avg loss: 0.211022 \n",
      "\n",
      "Epoch 27\n",
      "-------------------------------\n",
      "loss: 0.299169  [    0/ 5994]\n",
      "loss: 0.287671  [ 3200/ 5994]\n",
      "Test Error: \n",
      " Accuracy: 0.0%, Accuracy (Attribute-wise): 91.7%, Avg loss: 0.210648 \n",
      "\n",
      "Epoch 28\n",
      "-------------------------------\n",
      "loss: 0.278668  [    0/ 5994]\n",
      "loss: 0.304654  [ 3200/ 5994]\n",
      "Test Error: \n",
      " Accuracy: 0.0%, Accuracy (Attribute-wise): 91.7%, Avg loss: 0.210180 \n",
      "\n",
      "Epoch 29\n",
      "-------------------------------\n",
      "loss: 0.290810  [    0/ 5994]\n",
      "loss: 0.305740  [ 3200/ 5994]\n",
      "Test Error: \n",
      " Accuracy: 0.0%, Accuracy (Attribute-wise): 91.7%, Avg loss: 0.209764 \n",
      "\n",
      "Epoch 30\n",
      "-------------------------------\n",
      "loss: 0.275819  [    0/ 5994]\n",
      "loss: 0.292251  [ 3200/ 5994]\n",
      "Test Error: \n",
      " Accuracy: 0.0%, Accuracy (Attribute-wise): 91.7%, Avg loss: 0.209311 \n",
      "\n",
      "Epoch 31\n",
      "-------------------------------\n",
      "loss: 0.301246  [    0/ 5994]\n",
      "loss: 0.314579  [ 3200/ 5994]\n",
      "Test Error: \n",
      " Accuracy: 0.0%, Accuracy (Attribute-wise): 91.8%, Avg loss: 0.208975 \n",
      "\n",
      "Epoch 32\n",
      "-------------------------------\n",
      "loss: 0.307009  [    0/ 5994]\n",
      "loss: 0.314775  [ 3200/ 5994]\n",
      "Test Error: \n",
      " Accuracy: 0.0%, Accuracy (Attribute-wise): 91.8%, Avg loss: 0.208435 \n",
      "\n",
      "Epoch 33\n",
      "-------------------------------\n",
      "loss: 0.286021  [    0/ 5994]\n",
      "loss: 0.285527  [ 3200/ 5994]\n",
      "Test Error: \n",
      " Accuracy: 0.0%, Accuracy (Attribute-wise): 91.8%, Avg loss: 0.208368 \n",
      "\n",
      "Epoch 34\n",
      "-------------------------------\n",
      "loss: 0.290592  [    0/ 5994]\n",
      "loss: 0.272132  [ 3200/ 5994]\n",
      "Test Error: \n",
      " Accuracy: 0.0%, Accuracy (Attribute-wise): 91.8%, Avg loss: 0.208015 \n",
      "\n",
      "Epoch 35\n",
      "-------------------------------\n",
      "loss: 0.307614  [    0/ 5994]\n",
      "loss: 0.304940  [ 3200/ 5994]\n",
      "Test Error: \n",
      " Accuracy: 0.0%, Accuracy (Attribute-wise): 91.8%, Avg loss: 0.207677 \n",
      "\n",
      "Epoch 36\n",
      "-------------------------------\n",
      "loss: 0.319678  [    0/ 5994]\n",
      "loss: 0.313385  [ 3200/ 5994]\n",
      "Test Error: \n",
      " Accuracy: 0.0%, Accuracy (Attribute-wise): 91.8%, Avg loss: 0.207422 \n",
      "\n",
      "Epoch 37\n",
      "-------------------------------\n",
      "loss: 0.285500  [    0/ 5994]\n",
      "loss: 0.324434  [ 3200/ 5994]\n",
      "Test Error: \n",
      " Accuracy: 0.0%, Accuracy (Attribute-wise): 91.8%, Avg loss: 0.207403 \n",
      "\n",
      "Epoch 38\n",
      "-------------------------------\n",
      "loss: 0.275465  [    0/ 5994]\n",
      "loss: 0.320502  [ 3200/ 5994]\n",
      "Test Error: \n",
      " Accuracy: 0.0%, Accuracy (Attribute-wise): 91.8%, Avg loss: 0.206869 \n",
      "\n",
      "Epoch 39\n",
      "-------------------------------\n",
      "loss: 0.295546  [    0/ 5994]\n",
      "loss: 0.319690  [ 3200/ 5994]\n",
      "Test Error: \n",
      " Accuracy: 0.0%, Accuracy (Attribute-wise): 91.8%, Avg loss: 0.206810 \n",
      "\n",
      "Epoch 40\n",
      "-------------------------------\n",
      "loss: 0.280683  [    0/ 5994]\n",
      "loss: 0.315515  [ 3200/ 5994]\n",
      "Test Error: \n",
      " Accuracy: 0.0%, Accuracy (Attribute-wise): 91.8%, Avg loss: 0.206465 \n",
      "\n",
      "Epoch 41\n",
      "-------------------------------\n",
      "loss: 0.270623  [    0/ 5994]\n",
      "loss: 0.283659  [ 3200/ 5994]\n",
      "Test Error: \n",
      " Accuracy: 0.0%, Accuracy (Attribute-wise): 91.9%, Avg loss: 0.206079 \n",
      "\n",
      "Epoch 42\n",
      "-------------------------------\n",
      "loss: 0.303286  [    0/ 5994]\n",
      "loss: 0.327602  [ 3200/ 5994]\n",
      "Test Error: \n",
      " Accuracy: 0.0%, Accuracy (Attribute-wise): 91.8%, Avg loss: 0.206018 \n",
      "\n",
      "Epoch 43\n",
      "-------------------------------\n",
      "loss: 0.293483  [    0/ 5994]\n",
      "loss: 0.279499  [ 3200/ 5994]\n",
      "Test Error: \n",
      " Accuracy: 0.0%, Accuracy (Attribute-wise): 91.9%, Avg loss: 0.205946 \n",
      "\n",
      "Epoch 44\n",
      "-------------------------------\n",
      "loss: 0.289077  [    0/ 5994]\n",
      "loss: 0.293831  [ 3200/ 5994]\n",
      "Test Error: \n",
      " Accuracy: 0.0%, Accuracy (Attribute-wise): 91.9%, Avg loss: 0.205727 \n",
      "\n",
      "Epoch 45\n",
      "-------------------------------\n",
      "loss: 0.264704  [    0/ 5994]\n",
      "loss: 0.280579  [ 3200/ 5994]\n",
      "Test Error: \n",
      " Accuracy: 0.0%, Accuracy (Attribute-wise): 91.9%, Avg loss: 0.205777 \n",
      "\n",
      "Epoch 46\n",
      "-------------------------------\n",
      "loss: 0.278117  [    0/ 5994]\n",
      "loss: 0.276564  [ 3200/ 5994]\n",
      "Test Error: \n",
      " Accuracy: 0.0%, Accuracy (Attribute-wise): 91.9%, Avg loss: 0.205490 \n",
      "\n",
      "Epoch 47\n",
      "-------------------------------\n",
      "loss: 0.259084  [    0/ 5994]\n",
      "loss: 0.287976  [ 3200/ 5994]\n",
      "Test Error: \n",
      " Accuracy: 0.0%, Accuracy (Attribute-wise): 91.9%, Avg loss: 0.205202 \n",
      "\n",
      "Epoch 48\n",
      "-------------------------------\n",
      "loss: 0.298245  [    0/ 5994]\n",
      "loss: 0.277351  [ 3200/ 5994]\n",
      "Test Error: \n",
      " Accuracy: 0.0%, Accuracy (Attribute-wise): 91.9%, Avg loss: 0.205126 \n",
      "\n",
      "Epoch 49\n",
      "-------------------------------\n",
      "loss: 0.287921  [    0/ 5994]\n",
      "loss: 0.305946  [ 3200/ 5994]\n",
      "Test Error: \n",
      " Accuracy: 0.0%, Accuracy (Attribute-wise): 91.9%, Avg loss: 0.204998 \n",
      "\n",
      "Epoch 50\n",
      "-------------------------------\n",
      "loss: 0.277377  [    0/ 5994]\n",
      "loss: 0.322313  [ 3200/ 5994]\n",
      "Test Error: \n",
      " Accuracy: 0.0%, Accuracy (Attribute-wise): 91.9%, Avg loss: 0.204844 \n",
      "\n",
      "Epoch 51\n",
      "-------------------------------\n",
      "loss: 0.284769  [    0/ 5994]\n",
      "loss: 0.278168  [ 3200/ 5994]\n",
      "Test Error: \n",
      " Accuracy: 0.0%, Accuracy (Attribute-wise): 91.9%, Avg loss: 0.204855 \n",
      "\n",
      "Epoch 52\n",
      "-------------------------------\n",
      "loss: 0.263710  [    0/ 5994]\n",
      "loss: 0.247461  [ 3200/ 5994]\n",
      "Test Error: \n",
      " Accuracy: 0.0%, Accuracy (Attribute-wise): 91.9%, Avg loss: 0.204660 \n",
      "\n",
      "Epoch 53\n",
      "-------------------------------\n",
      "loss: 0.276890  [    0/ 5994]\n",
      "loss: 0.261666  [ 3200/ 5994]\n",
      "Test Error: \n",
      " Accuracy: 0.0%, Accuracy (Attribute-wise): 91.9%, Avg loss: 0.204748 \n",
      "\n",
      "Epoch 54\n",
      "-------------------------------\n",
      "loss: 0.277998  [    0/ 5994]\n",
      "loss: 0.278221  [ 3200/ 5994]\n",
      "Test Error: \n",
      " Accuracy: 0.0%, Accuracy (Attribute-wise): 91.9%, Avg loss: 0.204284 \n",
      "\n",
      "Epoch 55\n",
      "-------------------------------\n",
      "loss: 0.325110  [    0/ 5994]\n",
      "loss: 0.267965  [ 3200/ 5994]\n",
      "Test Error: \n",
      " Accuracy: 0.0%, Accuracy (Attribute-wise): 91.9%, Avg loss: 0.204350 \n",
      "\n",
      "Epoch 56\n",
      "-------------------------------\n",
      "loss: 0.307637  [    0/ 5994]\n",
      "loss: 0.290910  [ 3200/ 5994]\n",
      "Test Error: \n",
      " Accuracy: 0.0%, Accuracy (Attribute-wise): 91.9%, Avg loss: 0.204116 \n",
      "\n",
      "Epoch 57\n",
      "-------------------------------\n",
      "loss: 0.263782  [    0/ 5994]\n",
      "loss: 0.298773  [ 3200/ 5994]\n",
      "Test Error: \n",
      " Accuracy: 0.0%, Accuracy (Attribute-wise): 91.9%, Avg loss: 0.204287 \n",
      "\n",
      "Epoch 58\n",
      "-------------------------------\n",
      "loss: 0.280424  [    0/ 5994]\n",
      "loss: 0.258784  [ 3200/ 5994]\n",
      "Test Error: \n",
      " Accuracy: 0.0%, Accuracy (Attribute-wise): 91.9%, Avg loss: 0.204234 \n",
      "\n",
      "Epoch 59\n",
      "-------------------------------\n",
      "loss: 0.296737  [    0/ 5994]\n",
      "loss: 0.231336  [ 3200/ 5994]\n",
      "Test Error: \n",
      " Accuracy: 0.0%, Accuracy (Attribute-wise): 91.9%, Avg loss: 0.204299 \n",
      "\n",
      "Epoch 60\n",
      "-------------------------------\n",
      "loss: 0.285177  [    0/ 5994]\n",
      "loss: 0.287921  [ 3200/ 5994]\n",
      "Test Error: \n",
      " Accuracy: 0.0%, Accuracy (Attribute-wise): 91.9%, Avg loss: 0.204071 \n",
      "\n",
      "Epoch 61\n",
      "-------------------------------\n",
      "loss: 0.270875  [    0/ 5994]\n",
      "loss: 0.282379  [ 3200/ 5994]\n",
      "Test Error: \n",
      " Accuracy: 0.0%, Accuracy (Attribute-wise): 91.9%, Avg loss: 0.204618 \n",
      "\n",
      "Epoch 62\n",
      "-------------------------------\n",
      "loss: 0.249135  [    0/ 5994]\n",
      "loss: 0.299202  [ 3200/ 5994]\n",
      "Test Error: \n",
      " Accuracy: 0.0%, Accuracy (Attribute-wise): 91.9%, Avg loss: 0.204179 \n",
      "\n",
      "Epoch 63\n",
      "-------------------------------\n",
      "loss: 0.282031  [    0/ 5994]\n",
      "loss: 0.268433  [ 3200/ 5994]\n",
      "Test Error: \n",
      " Accuracy: 0.0%, Accuracy (Attribute-wise): 91.9%, Avg loss: 0.204615 \n",
      "\n",
      "Epoch 64\n",
      "-------------------------------\n",
      "loss: 0.267946  [    0/ 5994]\n",
      "loss: 0.277746  [ 3200/ 5994]\n",
      "Test Error: \n",
      " Accuracy: 0.0%, Accuracy (Attribute-wise): 91.9%, Avg loss: 0.204105 \n",
      "\n",
      "Epoch 65\n",
      "-------------------------------\n",
      "loss: 0.279694  [    0/ 5994]\n",
      "loss: 0.293454  [ 3200/ 5994]\n",
      "Test Error: \n",
      " Accuracy: 0.0%, Accuracy (Attribute-wise): 91.9%, Avg loss: 0.204414 \n",
      "\n",
      "Epoch 66\n",
      "-------------------------------\n",
      "loss: 0.280386  [    0/ 5994]\n",
      "loss: 0.258512  [ 3200/ 5994]\n",
      "Test Error: \n",
      " Accuracy: 0.0%, Accuracy (Attribute-wise): 91.9%, Avg loss: 0.203983 \n",
      "\n",
      "Epoch 67\n",
      "-------------------------------\n",
      "loss: 0.295478  [    0/ 5994]\n",
      "loss: 0.290435  [ 3200/ 5994]\n",
      "Test Error: \n",
      " Accuracy: 0.0%, Accuracy (Attribute-wise): 91.9%, Avg loss: 0.204053 \n",
      "\n",
      "Epoch 68\n",
      "-------------------------------\n",
      "loss: 0.246512  [    0/ 5994]\n",
      "loss: 0.277558  [ 3200/ 5994]\n",
      "Test Error: \n",
      " Accuracy: 0.0%, Accuracy (Attribute-wise): 91.9%, Avg loss: 0.204110 \n",
      "\n",
      "Epoch 69\n",
      "-------------------------------\n",
      "loss: 0.271432  [    0/ 5994]\n",
      "loss: 0.282769  [ 3200/ 5994]\n",
      "Test Error: \n",
      " Accuracy: 0.0%, Accuracy (Attribute-wise): 91.9%, Avg loss: 0.204420 \n",
      "\n",
      "Epoch 70\n",
      "-------------------------------\n",
      "loss: 0.292672  [    0/ 5994]\n",
      "loss: 0.272393  [ 3200/ 5994]\n",
      "Test Error: \n",
      " Accuracy: 0.0%, Accuracy (Attribute-wise): 91.9%, Avg loss: 0.203874 \n",
      "\n",
      "Epoch 71\n",
      "-------------------------------\n",
      "loss: 0.265054  [    0/ 5994]\n",
      "loss: 0.288813  [ 3200/ 5994]\n",
      "Test Error: \n",
      " Accuracy: 0.0%, Accuracy (Attribute-wise): 91.9%, Avg loss: 0.204378 \n",
      "\n",
      "Epoch 72\n",
      "-------------------------------\n",
      "loss: 0.268423  [    0/ 5994]\n",
      "loss: 0.286388  [ 3200/ 5994]\n",
      "Test Error: \n",
      " Accuracy: 0.0%, Accuracy (Attribute-wise): 91.9%, Avg loss: 0.203956 \n",
      "\n",
      "Epoch 73\n",
      "-------------------------------\n",
      "loss: 0.271104  [    0/ 5994]\n",
      "loss: 0.287543  [ 3200/ 5994]\n",
      "Test Error: \n",
      " Accuracy: 0.0%, Accuracy (Attribute-wise): 91.9%, Avg loss: 0.203866 \n",
      "\n",
      "Epoch 74\n",
      "-------------------------------\n",
      "loss: 0.270303  [    0/ 5994]\n",
      "loss: 0.288953  [ 3200/ 5994]\n",
      "Test Error: \n",
      " Accuracy: 0.0%, Accuracy (Attribute-wise): 91.9%, Avg loss: 0.203993 \n",
      "\n",
      "Epoch 75\n",
      "-------------------------------\n",
      "loss: 0.259463  [    0/ 5994]\n",
      "loss: 0.264885  [ 3200/ 5994]\n",
      "Test Error: \n",
      " Accuracy: 0.0%, Accuracy (Attribute-wise): 91.9%, Avg loss: 0.204331 \n",
      "\n",
      "Epoch 76\n",
      "-------------------------------\n",
      "loss: 0.245898  [    0/ 5994]\n",
      "loss: 0.272023  [ 3200/ 5994]\n",
      "Test Error: \n",
      " Accuracy: 0.0%, Accuracy (Attribute-wise): 91.9%, Avg loss: 0.204201 \n",
      "\n",
      "Epoch 77\n",
      "-------------------------------\n",
      "loss: 0.261374  [    0/ 5994]\n",
      "loss: 0.261833  [ 3200/ 5994]\n",
      "Test Error: \n",
      " Accuracy: 0.0%, Accuracy (Attribute-wise): 91.9%, Avg loss: 0.205148 \n",
      "\n",
      "Epoch 78\n",
      "-------------------------------\n",
      "loss: 0.264531  [    0/ 5994]\n",
      "loss: 0.259055  [ 3200/ 5994]\n",
      "Test Error: \n",
      " Accuracy: 0.0%, Accuracy (Attribute-wise): 91.9%, Avg loss: 0.204453 \n",
      "\n",
      "Epoch 79\n",
      "-------------------------------\n",
      "loss: 0.261497  [    0/ 5994]\n",
      "loss: 0.252183  [ 3200/ 5994]\n",
      "Test Error: \n",
      " Accuracy: 0.0%, Accuracy (Attribute-wise): 91.9%, Avg loss: 0.204250 \n",
      "\n",
      "Epoch 80\n",
      "-------------------------------\n",
      "loss: 0.275896  [    0/ 5994]\n",
      "loss: 0.239557  [ 3200/ 5994]\n",
      "Test Error: \n",
      " Accuracy: 0.0%, Accuracy (Attribute-wise): 91.9%, Avg loss: 0.204293 \n",
      "\n",
      "Epoch 81\n",
      "-------------------------------\n",
      "loss: 0.261296  [    0/ 5994]\n",
      "loss: 0.262978  [ 3200/ 5994]\n",
      "Test Error: \n",
      " Accuracy: 0.0%, Accuracy (Attribute-wise): 91.9%, Avg loss: 0.204017 \n",
      "\n",
      "Epoch 82\n",
      "-------------------------------\n",
      "loss: 0.274932  [    0/ 5994]\n",
      "loss: 0.270082  [ 3200/ 5994]\n",
      "Test Error: \n",
      " Accuracy: 0.0%, Accuracy (Attribute-wise): 91.9%, Avg loss: 0.204681 \n",
      "\n",
      "Epoch 83\n",
      "-------------------------------\n",
      "loss: 0.289511  [    0/ 5994]\n",
      "loss: 0.259827  [ 3200/ 5994]\n",
      "Test Error: \n",
      " Accuracy: 0.0%, Accuracy (Attribute-wise): 91.9%, Avg loss: 0.204888 \n",
      "\n",
      "Epoch 84\n",
      "-------------------------------\n",
      "loss: 0.260325  [    0/ 5994]\n",
      "loss: 0.278865  [ 3200/ 5994]\n",
      "Test Error: \n",
      " Accuracy: 0.0%, Accuracy (Attribute-wise): 91.9%, Avg loss: 0.204492 \n",
      "\n",
      "Epoch 85\n",
      "-------------------------------\n",
      "loss: 0.259500  [    0/ 5994]\n",
      "loss: 0.256913  [ 3200/ 5994]\n",
      "Test Error: \n",
      " Accuracy: 0.0%, Accuracy (Attribute-wise): 91.9%, Avg loss: 0.204906 \n",
      "\n",
      "Epoch 86\n",
      "-------------------------------\n",
      "loss: 0.280934  [    0/ 5994]\n",
      "loss: 0.263085  [ 3200/ 5994]\n",
      "Test Error: \n",
      " Accuracy: 0.0%, Accuracy (Attribute-wise): 91.9%, Avg loss: 0.204719 \n",
      "\n",
      "Epoch 87\n",
      "-------------------------------\n",
      "loss: 0.285016  [    0/ 5994]\n",
      "loss: 0.271704  [ 3200/ 5994]\n",
      "Test Error: \n",
      " Accuracy: 0.0%, Accuracy (Attribute-wise): 91.9%, Avg loss: 0.204862 \n",
      "\n",
      "Epoch 88\n",
      "-------------------------------\n",
      "loss: 0.306011  [    0/ 5994]\n",
      "loss: 0.299206  [ 3200/ 5994]\n",
      "Test Error: \n",
      " Accuracy: 0.0%, Accuracy (Attribute-wise): 91.9%, Avg loss: 0.204505 \n",
      "\n",
      "Epoch 89\n",
      "-------------------------------\n",
      "loss: 0.238178  [    0/ 5994]\n",
      "loss: 0.259389  [ 3200/ 5994]\n",
      "Test Error: \n",
      " Accuracy: 0.0%, Accuracy (Attribute-wise): 91.9%, Avg loss: 0.204724 \n",
      "\n",
      "Epoch 90\n",
      "-------------------------------\n",
      "loss: 0.240753  [    0/ 5994]\n",
      "loss: 0.282501  [ 3200/ 5994]\n",
      "Test Error: \n",
      " Accuracy: 0.0%, Accuracy (Attribute-wise): 91.9%, Avg loss: 0.205139 \n",
      "\n",
      "Epoch 91\n",
      "-------------------------------\n",
      "loss: 0.272328  [    0/ 5994]\n",
      "loss: 0.223196  [ 3200/ 5994]\n",
      "Test Error: \n",
      " Accuracy: 0.0%, Accuracy (Attribute-wise): 91.9%, Avg loss: 0.204499 \n",
      "\n",
      "Epoch 92\n",
      "-------------------------------\n",
      "loss: 0.244080  [    0/ 5994]\n",
      "loss: 0.243702  [ 3200/ 5994]\n",
      "Test Error: \n",
      " Accuracy: 0.0%, Accuracy (Attribute-wise): 91.9%, Avg loss: 0.204989 \n",
      "\n",
      "Epoch 93\n",
      "-------------------------------\n",
      "loss: 0.256571  [    0/ 5994]\n",
      "loss: 0.244346  [ 3200/ 5994]\n",
      "Test Error: \n",
      " Accuracy: 0.0%, Accuracy (Attribute-wise): 91.9%, Avg loss: 0.204755 \n",
      "\n",
      "Epoch 94\n",
      "-------------------------------\n",
      "loss: 0.249188  [    0/ 5994]\n",
      "loss: 0.258135  [ 3200/ 5994]\n",
      "Test Error: \n",
      " Accuracy: 0.0%, Accuracy (Attribute-wise): 91.9%, Avg loss: 0.205559 \n",
      "\n",
      "Epoch 95\n",
      "-------------------------------\n",
      "loss: 0.243683  [    0/ 5994]\n",
      "loss: 0.258886  [ 3200/ 5994]\n",
      "Test Error: \n",
      " Accuracy: 0.0%, Accuracy (Attribute-wise): 91.9%, Avg loss: 0.204847 \n",
      "\n",
      "Epoch 96\n",
      "-------------------------------\n",
      "loss: 0.260315  [    0/ 5994]\n",
      "loss: 0.225230  [ 3200/ 5994]\n",
      "Test Error: \n",
      " Accuracy: 0.0%, Accuracy (Attribute-wise): 91.9%, Avg loss: 0.205378 \n",
      "\n",
      "Epoch 97\n",
      "-------------------------------\n",
      "loss: 0.243754  [    0/ 5994]\n",
      "loss: 0.263413  [ 3200/ 5994]\n",
      "Test Error: \n",
      " Accuracy: 0.0%, Accuracy (Attribute-wise): 91.9%, Avg loss: 0.205594 \n",
      "\n",
      "Epoch 98\n",
      "-------------------------------\n",
      "loss: 0.245936  [    0/ 5994]\n",
      "loss: 0.281195  [ 3200/ 5994]\n",
      "Test Error: \n",
      " Accuracy: 0.0%, Accuracy (Attribute-wise): 91.9%, Avg loss: 0.205915 \n",
      "\n",
      "Epoch 99\n",
      "-------------------------------\n",
      "loss: 0.246481  [    0/ 5994]\n",
      "loss: 0.284806  [ 3200/ 5994]\n",
      "Test Error: \n",
      " Accuracy: 0.0%, Accuracy (Attribute-wise): 91.9%, Avg loss: 0.206207 \n",
      "\n",
      "Epoch 100\n",
      "-------------------------------\n",
      "loss: 0.256051  [    0/ 5994]\n",
      "loss: 0.248330  [ 3200/ 5994]\n",
      "Test Error: \n",
      " Accuracy: 0.0%, Accuracy (Attribute-wise): 91.9%, Avg loss: 0.205942 \n",
      "\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "epochs = 100\n",
    "max_acc = 0\n",
    "for t in range(epochs):\n",
    "    print(f\"Epoch {t+1}\\n-------------------------------\")\n",
    "    train(train_dataloader, model, loss_fn, optimizer)\n",
    "    curr_acc = test(test_dataloader, model, loss_fn)\n",
    "    if curr_acc > max_acc:\n",
    "        torch.save(model.state_dict(), \"independent_image_to_attributes.pth\")\n",
    "        max_acc = curr_acc\n",
    "print(\"Done!\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.8 ('.venv': poetry)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "b5aff9b338e2feb824080405e67a5c92dbce3d494c897e66331f024c87495a0f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
